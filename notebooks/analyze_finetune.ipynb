{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# from confusion import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(idx2category, labels_all_finetune, logits_all_finetune):\n",
    "    # modelnet_dict = torch.load(\"src/eval_data/modelnet_dict.pt\")\n",
    "\n",
    "    cat_list = list(idx2category.values())\n",
    "    \n",
    "    print(\"labels_all: \", labels_all_finetune.shape)\n",
    "    \n",
    "    _, pred = logits_all_finetune.topk(1, 1, True, True)\n",
    "    pred = pred.reshape(-1)\n",
    "    \n",
    "    true_pred = torch.argwhere(pred == labels_all_finetune).reshape(-1)\n",
    "    false_pred = torch.argwhere(pred != labels_all_finetune).reshape(-1)\n",
    "    \n",
    "    res = torch.zeros(len(cat_list), len(cat_list))\n",
    "    for val in true_pred:\n",
    "        idx = val.item()\n",
    "        res[labels_all_finetune[idx], pred[idx]] += 1\n",
    "    \n",
    "    for val in false_pred:\n",
    "        idx = val.item()\n",
    "        res[labels_all_finetune[idx], pred[idx]] += 1\n",
    "        # print(labels_all[idx], pred[idx])\n",
    "\n",
    "    \n",
    "    res_norm = F.softmax(res, dim=1)\n",
    "\n",
    "    return res, res_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx2category():\n",
    "    objaverse_dict = torch.load(\"../src/eval_data/objaverse_dict.pt\")\n",
    "    return objaverse_dict[\"idx2category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ov_res_norm = torch.load(\"src/eval_data/ov_confusion_norm.pt\")\n",
    "# ov_confusion_baseline = torch.load(\"src/eval_data/ov_confusion.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[464, 409, 861]\n",
    "[372, 510]\n",
    "[106, 548]\n",
    "[1019, 1020, 562]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_pairs = [(464, 409), (464, 861), (372, 510), (106, 548), (1019, 1020), (1019, 562)]\n",
    "confusion_pairs = [(464, 464), (464, 409), (464, 861), (372, 372), (372, 510), (106, 106), (106, 548), (1019, 1019), (1019, 1020), (1019, 562)]\n",
    "all_finetune_cats = [464, 409, 861, 372, 510, 106, 548, 1019, 1020, 562]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goldfish',\n",
       " 'fish',\n",
       " 'salmon_(fish)',\n",
       " 'earphone',\n",
       " 'headset',\n",
       " 'blazer',\n",
       " 'jacket',\n",
       " 'teakettle',\n",
       " 'teapot',\n",
       " 'kettle']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2category = get_idx2category()\n",
    "cat_names = []\n",
    "for cat in all_finetune_cats:\n",
    "    cat_names.append(idx2category[cat])\n",
    "cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_labels_all_only_test = torch.load(\"exp/finetune@20231230-095000/results/ov_labels_all_only_test.pt\")\n",
    "ov_logits_all_only_test = torch.load(\"exp/finetune@20231230-095000/results/ov_logits_all_only_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_all:  torch.Size([135])\n",
      "labels_all:  torch.Size([135])\n"
     ]
    }
   ],
   "source": [
    "epoch = 70\n",
    "if epoch is not None:\n",
    "    ov_labels_all_finetune = torch.load(f\"exp/finetune@20231230-095000/results/ov_labels_all_epoch_{epoch}.pt\")\n",
    "    ov_logits_all_finetune = torch.load(f\"exp/finetune@20231230-095000/results/ov_logits_all_epoch_{epoch}.pt\")\n",
    "\n",
    "idx2category = get_idx2category()\n",
    "ov_res_finetune, ov_res_norm_finetune = plot_confusion_matrix(idx2category, ov_labels_all_finetune, ov_logits_all_finetune)\n",
    "ov_res_baseline, _ = plot_confusion_matrix(idx2category, ov_labels_all_only_test, ov_logits_all_only_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:  goldfish\n",
      "objaverse: correct - 4.0, confusion - 8.0\n",
      "finetune: correct - 4.0, confusion - 0.0\n",
      "\n",
      "\n",
      "category:  earphone\n",
      "objaverse: correct - 6.0, confusion - 11.0\n",
      "finetune: correct - 0.0, confusion - 2.0\n",
      "\n",
      "\n",
      "category:  blazer\n",
      "objaverse: correct - 0.0, confusion - 7.0\n",
      "finetune: correct - 0.0, confusion - 1.0\n",
      "\n",
      "\n",
      "category:  teakettle\n",
      "objaverse: correct - 3.0, confusion - 11.0\n",
      "finetune: correct - 1.0, confusion - 2.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"category: \", idx2category[464])\n",
    "print(f\"objaverse: correct - {ov_res_baseline[464, 464]}, confusion - {ov_res_baseline[464, 409] + ov_res_baseline[464, 861]}\")\n",
    "print(f\"finetune: correct - {ov_res_finetune[464, 464]}, confusion - {ov_res_finetune[464, 409] + ov_res_finetune[464, 861]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"category: \", idx2category[372])\n",
    "print(f\"objaverse: correct - {ov_res_baseline[372, 372]}, confusion - {ov_res_baseline[372, 510]}\")\n",
    "print(f\"finetune: correct - {ov_res_finetune[372, 372]}, confusion - {ov_res_finetune[372, 510]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"category: \", idx2category[106])\n",
    "print(f\"objaverse: correct - {ov_res_baseline[106, 106]}, confusion - {ov_res_baseline[106, 548]}\")\n",
    "print(f\"finetune: correct - {ov_res_finetune[106, 106]}, confusion - {ov_res_finetune[106, 548]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"category: \", idx2category[1019])\n",
    "print(f\"objaverse: correct - {ov_res_baseline[1019, 1019]}, confusion - {ov_res_baseline[1019, 1020] + ov_res_baseline[1019, 562]}\")\n",
    "print(f\"finetune: correct - {ov_res_finetune[1019, 1019]}, confusion - {ov_res_finetune[1019, 1020] + ov_res_finetune[1019, 562]}\")\n",
    "print(\"\\n\")\n",
    "# print(\"objaverse: \", ov_res_baseline[464, 464]/(ov_res_baseline[464, 409] + ov_res_baseline[464, 861]))\n",
    "# print(\"finetune: \", ov_res_finetune[464, 464]/(ov_res_finetune[464, 409] + ov_res_finetune[464, 861]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_all:  torch.Size([46205])\n",
      "labels_all:  torch.Size([46205])\n"
     ]
    }
   ],
   "source": [
    "epoch = 60\n",
    "idx2category = get_idx2category()\n",
    "ov_labels_all_finetune_ov_test_all = torch.load(\"exp/finetune@20231230-095000/results/ov_labels_all_finetune_ov_test_all.pt\")\n",
    "ov_logits_all_finetune_ov_test_all = torch.load(\"exp/finetune@20231230-095000/results/ov_logits_all_finetune_ov_test_all.pt\")\n",
    "\n",
    "ov_labels_all_finetune_ov_test_all_epoch = torch.load(f\"exp/finetune@20231230-095000/results/ov_labels_all_finetune_ov_test_all_epoch_{epoch}.pt\")\n",
    "ov_logits_all_finetune_ov_test_all_epoch = torch.load(f\"exp/finetune@20231230-095000/results/ov_logits_all_finetune_ov_test_all_epoch_{epoch}.pt\")\n",
    "\n",
    "# print(\"labels_all: \", ov_labels_all_finetune_ov_test_all_epoch_50.shape)\n",
    "# print(\"labels_all: \", ov_labels_all_finetune_ov_test_all.shape)\n",
    "ov_res_finetune, ov_res_norm_finetune = plot_confusion_matrix(idx2category, ov_labels_all_finetune_ov_test_all_epoch, ov_logits_all_finetune_ov_test_all_epoch)\n",
    "ov_res_baseline, _ = plot_confusion_matrix(idx2category, ov_labels_all_finetune_ov_test_all, ov_logits_all_finetune_ov_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:  goldfish\n",
      "objaverse: correct - 18.0, confusion - 38.0\n",
      "finetune: correct - 8.0, confusion - 7.0\n",
      "\n",
      "\n",
      "category:  earphone\n",
      "objaverse: correct - 28.0, confusion - 52.0\n",
      "finetune: correct - 5.0, confusion - 3.0\n",
      "\n",
      "\n",
      "category:  blazer\n",
      "objaverse: correct - 1.0, confusion - 32.0\n",
      "finetune: correct - 0.0, confusion - 1.0\n",
      "\n",
      "\n",
      "category:  teakettle\n",
      "objaverse: correct - 6.0, confusion - 63.0\n",
      "finetune: correct - 3.0, confusion - 11.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"category: \", idx2category[464])\n",
    "print(f\"objaverse: correct - {ov_res_baseline[464, 464]}, confusion - {ov_res_baseline[464, 409] + ov_res_baseline[464, 861]}\")\n",
    "print(f\"finetune: correct - {ov_res_finetune[464, 464]}, confusion - {ov_res_finetune[464, 409] + ov_res_finetune[464, 861]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"category: \", idx2category[372])\n",
    "print(f\"objaverse: correct - {ov_res_baseline[372, 372]}, confusion - {ov_res_baseline[372, 510]}\")\n",
    "print(f\"finetune: correct - {ov_res_finetune[372, 372]}, confusion - {ov_res_finetune[372, 510]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"category: \", idx2category[106])\n",
    "print(f\"objaverse: correct - {ov_res_baseline[106, 106]}, confusion - {ov_res_baseline[106, 548]}\")\n",
    "print(f\"finetune: correct - {ov_res_finetune[106, 106]}, confusion - {ov_res_finetune[106, 548]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"category: \", idx2category[1019])\n",
    "print(f\"objaverse: correct - {ov_res_baseline[1019, 1019]}, confusion - {ov_res_baseline[1019, 1020] + ov_res_baseline[1019, 562]}\")\n",
    "print(f\"finetune: correct - {ov_res_finetune[1019, 1019]}, confusion - {ov_res_finetune[1019, 1020] + ov_res_finetune[1019, 562]}\")\n",
    "print(\"\\n\")\n",
    "# print(\"objaverse: \", ov_res_baseline[464, 464]/(ov_res_baseline[464, 409] + ov_res_baseline[464, 861]))\n",
    "# print(\"finetune: \", ov_res_finetune[464, 464]/(ov_res_finetune[464, 409] + ov_res_finetune[464, 861]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:  goldfish\n",
      "objaverse:  tensor(18.)\n",
      "finetune:  tensor(10.)\n",
      "\n",
      "\n",
      "category:  fish\n",
      "objaverse:  tensor(68.)\n",
      "finetune:  tensor(18.)\n",
      "\n",
      "\n",
      "category:  salmon_(fish)\n",
      "objaverse:  tensor(6.)\n",
      "finetune:  tensor(6.)\n",
      "\n",
      "\n",
      "category:  earphone\n",
      "objaverse:  tensor(28.)\n",
      "finetune:  tensor(4.)\n",
      "\n",
      "\n",
      "category:  headset\n",
      "objaverse:  tensor(60.)\n",
      "finetune:  tensor(9.)\n",
      "\n",
      "\n",
      "category:  blazer\n",
      "objaverse:  tensor(1.)\n",
      "finetune:  tensor(2.)\n",
      "\n",
      "\n",
      "category:  jacket\n",
      "objaverse:  tensor(37.)\n",
      "finetune:  tensor(2.)\n",
      "\n",
      "\n",
      "category:  teakettle\n",
      "objaverse:  tensor(6.)\n",
      "finetune:  tensor(3.)\n",
      "\n",
      "\n",
      "category:  teapot\n",
      "objaverse:  tensor(73.)\n",
      "finetune:  tensor(10.)\n",
      "\n",
      "\n",
      "category:  kettle\n",
      "objaverse:  tensor(16.)\n",
      "finetune:  tensor(7.)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in all_finetune_cats:\n",
    "    print(\"category: \", idx2category[cat])\n",
    "    print(\"objaverse: \", ov_res_baseline[cat, cat])\n",
    "    print(\"finetune: \", ov_res_finetune[cat, cat])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "lvis_filter_test = json.load(open(\"finetune/lvis_filter_test.json\", \"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(logits_all, labels_all, target_labels, topk=(1,)):    \n",
    "    per_cat_correct = torch.zeros(1156)\n",
    "    per_cat_count = torch.zeros(1156)\n",
    "    # calculate per class accuracy\n",
    "    for i in torch.unique(target_labels):\n",
    "        idx = (labels_all == i)\n",
    "        if idx.sum() > 0:\n",
    "            per_cat_correct[i] += (logits_all[idx].argmax(dim=1) == labels_all[idx]).float().sum()\n",
    "            per_cat_count[i] += idx.sum()\n",
    "\n",
    "    # topk_acc, correct = calc_accuracy(logits_all, labels_all, topk=(1,3,5,))\n",
    "    per_cat_correct = per_cat_correct[target_labels]\n",
    "    per_cat_count = per_cat_count[target_labels]\n",
    "    overall_acc = per_cat_correct.sum() / per_cat_count.sum()\n",
    "    per_cat_acc = per_cat_correct / per_cat_count\n",
    "\n",
    "    return overall_acc, per_cat_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc_finetune_ov_test_all, per_cat_acc_finetune_ov_test_all = calc_accuracy(ov_logits_all_finetune_ov_test_all, ov_labels_all_finetune_ov_test_all, torch.tensor(all_finetune_cats), topk=(1))\n",
    "overall_acc_finetune_ov_test_all_epoch, per_cat_acc_finetune_ov_test_all_epoch = calc_accuracy(ov_logits_all_finetune_ov_test_all_epoch, ov_labels_all_finetune_ov_test_all_epoch, torch.tensor(all_finetune_cats), topk=(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_acc:  0.4720965325832367\n",
      "per_cat_acc:  tensor([0.3158, 0.8500, 0.2069, 0.3011, 0.8333, 0.0167, 0.6981, 0.0870, 0.9733,\n",
      "        0.2133])\n"
     ]
    }
   ],
   "source": [
    "print(\"overall_acc: \", overall_acc_finetune_ov_test_all.item())\n",
    "print(\"per_cat_acc: \", per_cat_acc_finetune_ov_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_acc:  0.21116138994693756\n",
      "per_cat_acc:  tensor([0.3509, 0.4500, 0.3103, 0.0968, 0.3194, 0.0167, 0.0189, 0.0290, 0.3333,\n",
      "        0.1867])\n"
     ]
    }
   ],
   "source": [
    "print(\"overall_acc: \", overall_acc_finetune_ov_test_all_epoch.item())\n",
    "print(\"per_cat_acc: \", per_cat_acc_finetune_ov_test_all_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_labels_all_finetune_ov_test_all = torch.load(\"exp/finetune@20231230-095000/results/ov_labels_all_finetune_ov_test_all.pt\")\n",
    "ov_logits_all_finetune_ov_test_all = torch.load(\"exp/finetune@20231230-095000/results/ov_logits_all_finetune_ov_test_all.pt\")\n",
    "\n",
    "ov_labels_all_finetune_ov_test_all_epoch = torch.load(f\"exp/finetune@20231230-095000/results/ov_labels_all_finetune_ov_test_all_epoch_{epoch}.pt\")\n",
    "ov_logits_all_finetune_ov_test_all_epoch = torch.load(f\"exp/finetune@20231230-095000/results/ov_logits_all_finetune_ov_test_all_epoch_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 60\n",
    "ov_labels_all_finetune_ov_test_all = torch.load(\"exp/finetune_freeze@20240114-070152/results/ov_labels_all_finetune_test.pt\")\n",
    "ov_logits_all_finetune_ov_test_all = torch.load(\"exp/finetune_freeze@20240114-070152/results/ov_logits_all_finetune_test.pt\")\n",
    "\n",
    "ov_labels_all_finetune_ov_test_all_epoch = torch.load(f\"exp/finetune_freeze@20240114-070152/results/ov_labels_all_finetune_ov_test_all_epoch_{epoch}.pt\")\n",
    "ov_logits_all_finetune_ov_test_all_epoch = torch.load(f\"exp/finetune_freeze@20240114-070152/results/ov_logits_all_finetune_ov_test_all_epoch_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 60\n",
    "\n",
    "ov_labels_all_finetune_ov_test_all = torch.load(\"../exp/finetune_1layer@20240129-151703/results/ov_labels_all_finetune_test.pt\")\n",
    "ov_logits_all_finetune_ov_test_all = torch.load(\"../exp/finetune_1layer@20240129-151703/results/ov_logits_all_finetune_test.pt\")\n",
    "\n",
    "ov_labels_all_finetune_ov_test_all_epoch = torch.load(f\"../exp/finetune_1layer@20240129-151703/results/ov_labels_all_finetune_ov_test_all_epoch_{epoch}.pt\")\n",
    "ov_logits_all_finetune_ov_test_all_epoch = torch.load(f\"../exp/finetune_1layer@20240129-151703/results/ov_logits_all_finetune_ov_test_all_epoch_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc_finetune_ov_test_all, per_cat_acc_finetune_ov_test_all = calc_accuracy(ov_logits_all_finetune_ov_test_all, ov_labels_all_finetune_ov_test_all, torch.tensor(all_finetune_cats), topk=(1))\n",
    "overall_acc_finetune_ov_test_all_epoch, per_cat_acc_finetune_ov_test_all_epoch = calc_accuracy(ov_logits_all_finetune_ov_test_all_epoch, ov_labels_all_finetune_ov_test_all_epoch, torch.tensor(all_finetune_cats), topk=(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_acc:  0.4690799415111542\n",
      "per_cat_acc:  tensor([0.2982, 0.8500, 0.2069, 0.3011, 0.7778, 0.0167, 0.6792, 0.1014, 0.9867,\n",
      "        0.2400])\n",
      "class_acc:  tensor(0.4458)\n"
     ]
    }
   ],
   "source": [
    "print(\"overall_acc: \", overall_acc_finetune_ov_test_all.item())\n",
    "print(\"per_cat_acc: \", per_cat_acc_finetune_ov_test_all)\n",
    "print(\"class_acc: \", per_cat_acc_finetune_ov_test_all.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_acc:  0.4313725531101227\n",
      "per_cat_acc:  tensor([0.3158, 0.8000, 0.3448, 0.2366, 0.7500, 0.0000, 0.4906, 0.0870, 0.8800,\n",
      "        0.2667])\n",
      "class_acc:  tensor(0.4171)\n"
     ]
    }
   ],
   "source": [
    "print(\"overall_acc: \", overall_acc_finetune_ov_test_all_epoch.item())\n",
    "print(\"per_cat_acc: \", per_cat_acc_finetune_ov_test_all_epoch)\n",
    "print(\"class_acc: \", per_cat_acc_finetune_ov_test_all_epoch.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_labels_all_finetune = torch.load(\"exp/finetune_freeze@20240114-070152/results/ov_labels_all_finetune_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goldfish: 57\n",
      "fish: 80\n",
      "salmon_(fish): 29\n",
      "earphone: 93\n",
      "headset: 72\n",
      "blazer: 60\n",
      "jacket: 53\n",
      "teakettle: 69\n",
      "teapot: 75\n",
      "kettle: 75\n"
     ]
    }
   ],
   "source": [
    "all_finetune_cats\n",
    "\n",
    "for cat in all_finetune_cats:\n",
    "    print(f\"{idx2category[cat]}: {ov_labels_all_finetune[ov_labels_all_finetune == cat].shape[0]}\")\n",
    "    # print(\"objaverse: \", ov_labels_all_finetune[ov_labels_all_finetune == cat].shape[0])\n",
    "    # print(\"\\n\")\n",
    "# ov_labels_all_finetune[ov_labels_all_finetune == all_finetune_cats[0]].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
