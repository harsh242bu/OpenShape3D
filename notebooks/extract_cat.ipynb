{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../mnt/data/objaverse-processed/merged_for_training_final/Objaverse/000-152/e40a05dbe3704872bcc9dd49593c41d5.npy\"\n",
    "data = np.load(file, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_idx():\n",
    "    objaverse_dict = torch.load(\"../src/eval_data/objaverse_dict.pt\")\n",
    "    ov_category2idx = objaverse_dict[\"category2idx\"]\n",
    "    ov_idx2category = objaverse_dict[\"idx2category\"]\n",
    "\n",
    "    return ov_category2idx, ov_idx2category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"/projectnb/ivc-ml/harshk/3d_perception/OpenShape3D/meta_data/split/lvis.json\"\n",
    "ov_category2idx, ov_idx2category = get_cat_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finetuning 10 categories\n",
    "# cat_list = [464, 409, 861, 372, 510, 106, 548, 1019, 1020, 562]\n",
    "\n",
    "# cat_list = [328, 653] # desk - monitor_(computer_equipment) computer_monitor\n",
    "# cat_list = [29, 515] # armor - helmet\n",
    "# cat_list = [221, 1020] # chinaware - teapot\n",
    "cat_list = [20, 1138] # antenna - windmill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antenna\n",
      "windmill\n"
     ]
    }
   ],
   "source": [
    "for cat in cat_list:\n",
    "    print(ov_idx2category[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = json.load(open(test_file, \"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data = {}\n",
    "for i in cat_list:\n",
    "    filter_data[i] = []\n",
    "\n",
    "for obj in data_list:\n",
    "    cat_id = ov_category2idx[obj[\"category\"]]\n",
    "    if cat_id in cat_list:\n",
    "        filter_data[cat_id].append(obj)\n",
    "        # filter_data.append(obj)\n",
    "        # print(obj[\"category_id\"], obj[\"category_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../finetune/antenna_windmill/\"\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "file_name = os.path.join(dir, \"lvis_filtered.json\")\n",
    "\n",
    "json.dump(filter_data, open(file_name, \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for key, val in filter_data.items():\n",
    "    # print(key, len(val))\n",
    "    data_size = len(val)\n",
    "    random.shuffle(val)\n",
    "    train_size = int(train_split * data_size)\n",
    "    train_data[key] = val[:train_size]\n",
    "    test_data[key] = val[train_size:]\n",
    "\n",
    "json.dump(train_data, open(os.path.join(dir, \"lvis_filter_train.json\"), \"w\"), indent=4)\n",
    "json.dump(test_data, open(os.path.join(dir, \"lvis_filter_test.json\"), \"w\"), indent=4)\n",
    "# json.dump(train_data, open(\"finetune/lvis_filter_train.json\", \"w\"), indent=4)\n",
    "# json.dump(test_data, open(\"finetune/lvis_filter_test.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') \n",
    "all_text = json.load(open('all_text.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in random.choices(all_text, k=3):\n",
    "    doc = nlp(text)\n",
    "    print(\"text: \", text)\n",
    "    noun = None\n",
    "    adj = None\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            noun = token.text\n",
    "        elif token.pos_ == \"ADJ\":\n",
    "            adj = token.text\n",
    "        print(f\"{token.text}: {token.pos_}\")\n",
    "    # print(\"noun: \", noun, \"\\tadj: \", adj)\n",
    "    print(\"\\n\")\n",
    "        # print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #         token.shape_, token.is_alpha, token.is_stop)\n",
    "    # all_text[i] = cats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
