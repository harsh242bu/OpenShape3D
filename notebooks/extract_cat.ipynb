{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"mnt/data/objaverse-processed/merged_for_training_final/Objaverse/000-152/e40a05dbe3704872bcc9dd49593c41d5.npy\"\n",
    "data = np.load(file, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_idx():\n",
    "    objaverse_dict = torch.load(\"src/eval_data/objaverse_dict.pt\")\n",
    "    ov_category2idx = objaverse_dict[\"category2idx\"]\n",
    "    ov_idx2category = objaverse_dict[\"idx2category\"]\n",
    "\n",
    "    return ov_category2idx, ov_idx2category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"/projectnb/ivc-ml/harshk/3d_perception/OpenShape3D/meta_data/split/lvis.json\"\n",
    "ov_category2idx, ov_idx2category = get_cat_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = [464, 409, 861, 372, 510, 106, 548, 1019, 1020, 562]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = json.load(open(test_file, \"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data = {}\n",
    "for i in cat_list:\n",
    "    filter_data[i] = []\n",
    "\n",
    "for obj in data_list:\n",
    "    cat_id = ov_category2idx[obj[\"category\"]]\n",
    "    if cat_id in cat_list:\n",
    "        filter_data[cat_id].append(obj)\n",
    "        # filter_data.append(obj)\n",
    "        # print(obj[\"category_id\"], obj[\"category_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(filter_data, open(\"finetune/lvis_filtered.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for key, val in filter_data.items():\n",
    "    # print(key, len(val))\n",
    "    data_size = len(val)\n",
    "    random.shuffle(val)\n",
    "    train_size = int(0.8 * data_size)\n",
    "    train_data[key] = val[:train_size]\n",
    "    test_data[key] = val[train_size:]\n",
    "\n",
    "json.dump(train_data, open(\"finetune/lvis_filter_train.json\", \"w\"), indent=4)\n",
    "json.dump(test_data, open(\"finetune/lvis_filter_test.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 4, 14, 18, 12, 20, 8, 6, 2, 16]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') \n",
    "all_text = json.load(open('all_text.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in random.choices(all_text, k=3):\n",
    "    doc = nlp(text)\n",
    "    print(\"text: \", text)\n",
    "    noun = None\n",
    "    adj = None\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            noun = token.text\n",
    "        elif token.pos_ == \"ADJ\":\n",
    "            adj = token.text\n",
    "        print(f\"{token.text}: {token.pos_}\")\n",
    "    # print(\"noun: \", noun, \"\\tadj: \", adj)\n",
    "    print(\"\\n\")\n",
    "        # print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #         token.shape_, token.is_alpha, token.is_stop)\n",
    "    # all_text[i] = cats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
